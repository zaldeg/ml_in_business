{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "f7c604d00f38437f4df57123c10451e0676060e1a3eca5c56f25a4495d595057"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/HTRU2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    16259\n",
       "1     1639\n",
       "Name: 8, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 303
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"HTRU_2.csv\", header=None)\n",
    "data[8].value_counts()"
   ]
  },
  {
   "source": [
    "Взял не сбалансированный сет, на уроке показалось, что с таким должны быть проблемы, так как наша схема хорошо должна себя проявить на половине данных. В процессе станет понятно, если что уберу часть данных, сделаю сет сбалансированным."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 17898 entries, 0 to 17897\nData columns (total 9 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   0       17898 non-null  float64\n 1   1       17898 non-null  float64\n 2   2       17898 non-null  float64\n 3   3       17898 non-null  float64\n 4   4       17898 non-null  float64\n 5   5       17898 non-null  float64\n 6   6       17898 non-null  float64\n 7   7       17898 non-null  float64\n 8   8       17898 non-null  int64  \ndtypes: float64(8), int64(1)\nmemory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     count        mean         std        min         25%         50%  \\\n",
       "0  17898.0  111.079968   25.652935   5.812500  100.929688  115.078125   \n",
       "1  17898.0   46.549532    6.843189  24.772042   42.376018   46.947479   \n",
       "2  17898.0    0.477857    1.064040  -1.876011    0.027098    0.223240   \n",
       "3  17898.0    1.770279    6.167913  -1.791886   -0.188572    0.198710   \n",
       "4  17898.0   12.614400   29.472897   0.213211    1.923077    2.801839   \n",
       "5  17898.0   26.326515   19.470572   7.370432   14.437332   18.461316   \n",
       "6  17898.0    8.303556    4.506092  -3.139270    5.781506    8.433515   \n",
       "7  17898.0  104.857709  106.514540  -1.976976   34.960504   83.064556   \n",
       "8  17898.0    0.091574    0.288432   0.000000    0.000000    0.000000   \n",
       "\n",
       "          75%          max  \n",
       "0  127.085938   192.617188  \n",
       "1   51.023202    98.778911  \n",
       "2    0.473325     8.069522  \n",
       "3    0.927783    68.101622  \n",
       "4    5.464256   223.392140  \n",
       "5   28.428104   110.642211  \n",
       "6   10.702959    34.539844  \n",
       "7  139.309331  1191.000837  \n",
       "8    0.000000     1.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17898.0</td>\n      <td>111.079968</td>\n      <td>25.652935</td>\n      <td>5.812500</td>\n      <td>100.929688</td>\n      <td>115.078125</td>\n      <td>127.085938</td>\n      <td>192.617188</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17898.0</td>\n      <td>46.549532</td>\n      <td>6.843189</td>\n      <td>24.772042</td>\n      <td>42.376018</td>\n      <td>46.947479</td>\n      <td>51.023202</td>\n      <td>98.778911</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>17898.0</td>\n      <td>0.477857</td>\n      <td>1.064040</td>\n      <td>-1.876011</td>\n      <td>0.027098</td>\n      <td>0.223240</td>\n      <td>0.473325</td>\n      <td>8.069522</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17898.0</td>\n      <td>1.770279</td>\n      <td>6.167913</td>\n      <td>-1.791886</td>\n      <td>-0.188572</td>\n      <td>0.198710</td>\n      <td>0.927783</td>\n      <td>68.101622</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17898.0</td>\n      <td>12.614400</td>\n      <td>29.472897</td>\n      <td>0.213211</td>\n      <td>1.923077</td>\n      <td>2.801839</td>\n      <td>5.464256</td>\n      <td>223.392140</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>17898.0</td>\n      <td>26.326515</td>\n      <td>19.470572</td>\n      <td>7.370432</td>\n      <td>14.437332</td>\n      <td>18.461316</td>\n      <td>28.428104</td>\n      <td>110.642211</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>17898.0</td>\n      <td>8.303556</td>\n      <td>4.506092</td>\n      <td>-3.139270</td>\n      <td>5.781506</td>\n      <td>8.433515</td>\n      <td>10.702959</td>\n      <td>34.539844</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>17898.0</td>\n      <td>104.857709</td>\n      <td>106.514540</td>\n      <td>-1.976976</td>\n      <td>34.960504</td>\n      <td>83.064556</td>\n      <td>139.309331</td>\n      <td>1191.000837</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>17898.0</td>\n      <td>0.091574</td>\n      <td>0.288432</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 305
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "source": [
    "Данные полные, категориальных данных нету. Все данные вещественные. Так кк модель будет не линейной, то нормализация,стандартизация нам не нужна."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = data.iloc[:,:-1]\n",
    "y_data = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3580,)"
      ]
     },
     "metadata": {},
     "execution_count": 307
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat = CatBoostClassifier()\n",
    "\n",
    "cat.fit(x_train, y_train, verbose=False)\n",
    "y_predict = cat.predict(x_test)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification results:\nf1: 88.49%\nroc: 92.36%\nrecall: 85.55%\nprecision: 91.64%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "def evaluate_results(y_test, y_predict):\n",
    "    print('Classification results:')\n",
    "    f1 = f1_score(y_test, y_predict)\n",
    "    print(\"f1: %.2f%%\" % (f1 * 100.0)) \n",
    "    roc = roc_auc_score(y_test, y_predict)\n",
    "    print(\"roc: %.2f%%\" % (roc * 100.0)) \n",
    "    rec = recall_score(y_test, y_predict, average='binary')\n",
    "    print(\"recall: %.2f%%\" % (rec * 100.0)) \n",
    "    prc = precision_score(y_test, y_predict, average='binary')\n",
    "    print(\"precision: %.2f%%\" % (prc * 100.0)) \n",
    "\n",
    "    \n",
    "evaluate_results(y_test, y_predict)"
   ]
  },
  {
   "source": [
    "Получилось вроде норм"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using 164/1639 as positives and unlabeling the rest\n"
     ]
    }
   ],
   "source": [
    "mod_data = data.copy()\n",
    "#get the indices of the positives samples\n",
    "pos_ind = np.where(mod_data.iloc[:,-1].values == 1)[0]\n",
    "#shuffle them\n",
    "np.random.shuffle(pos_ind)\n",
    "# leave just 25% of the positives marked\n",
    "pos_sample_len = int(np.ceil(0.1 * len(pos_ind)))\n",
    "print(f'Using {pos_sample_len}/{len(pos_ind)} as positives and unlabeling the rest')\n",
    "pos_sample = pos_ind[:pos_sample_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "target variable:\n -1    17734\n 1      164\nName: class_test, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mod_data['class_test'] = -1\n",
    "mod_data.loc[pos_sample,'class_test'] = 1\n",
    "print('target variable:\\n', mod_data.iloc[:,-1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = mod_data.iloc[:,:-2].values # just the X \n",
    "y_labeled = mod_data.iloc[:,-1].values # new class (just the P & U)\n",
    "y_positive = mod_data.iloc[:,-2].values # original class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(164, 10) (164, 10)\n"
     ]
    }
   ],
   "source": [
    "mod_data = mod_data.sample(frac=1)\n",
    "neg_sample = mod_data[mod_data['class_test']==-1][:len(mod_data[mod_data['class_test']==1])]\n",
    "sample_test = mod_data[mod_data['class_test']==-1][len(mod_data[mod_data['class_test']==1]):]\n",
    "pos_sample = mod_data[mod_data['class_test']==1]\n",
    "print(neg_sample.shape, pos_sample.shape)\n",
    "sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17570, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 313
    }
   ],
   "source": [
    "sample_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification results:\nf1: 77.02%\nroc: 93.55%\nrecall: 91.26%\nprecision: 66.62%\n"
     ]
    }
   ],
   "source": [
    "cat = CatBoostClassifier()\n",
    "cat.fit(sample_train.iloc[:,:-2].values, \n",
    "          sample_train.iloc[:,-2].values, verbose=False)\n",
    "y_predict = cat.predict(sample_test.iloc[:,:-2].values)\n",
    "evaluate_results(sample_test.iloc[:,-2].values, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([15563,  2007], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 315
    }
   ],
   "source": [
    "np.bincount(y_predict)"
   ]
  },
  {
   "source": [
    "Соберем из этого подобие кросс валидации, так как выглядит как будто в процессе есть большая дисперсия."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_list(y_test, y_predict):\n",
    "    f1 = f1_score(y_test, y_predict)\n",
    "    roc = roc_auc_score(y_test, y_predict)\n",
    "    rec = recall_score(y_test, y_predict, average='binary')\n",
    "    prc = precision_score(y_test, y_predict, average='binary')\n",
    "    return [f1, roc, rec, prc]\n",
    "\n",
    "def some_fake_cv(data, cv=4, percent=0.1, verbose=False):\n",
    "    '''\n",
    "    data - our dataset\n",
    "    cv  - number of models for validation\n",
    "    percent - percent of positive samples have been taken\n",
    "\n",
    "    Return: list with metrics lists: [f1, roc, recall, precision]\n",
    "    '''\n",
    "\n",
    "    results = []\n",
    "    for i in range(cv):\n",
    "        mod_data = data.copy()\n",
    "        pos_ind = np.where(mod_data.iloc[:,-1].values == 1)[0]\n",
    "        np.random.shuffle(pos_ind)\n",
    "        pos_sample_len = int(np.ceil(percent * len(pos_ind)))\n",
    "        pos_sample = pos_ind[:pos_sample_len]\n",
    "        mod_data['class_test'] = -1\n",
    "        mod_data.loc[pos_sample,'class_test'] = 1\n",
    "        x_data = mod_data.iloc[:,:-2].values # just the X \n",
    "        y_labeled = mod_data.iloc[:,-1].values # new class (just the P & U)\n",
    "        y_positive = mod_data.iloc[:,-2].values # original class\n",
    "        mod_data = mod_data.sample(frac=1)\n",
    "        neg_sample = mod_data[mod_data['class_test']==-1][:len(mod_data[mod_data['class_test']==1])]\n",
    "        sample_test = mod_data[mod_data['class_test']==-1][len(mod_data[mod_data['class_test']==1]):]\n",
    "        pos_sample = mod_data[mod_data['class_test']==1]\n",
    "        sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)\n",
    "        cat = CatBoostClassifier()\n",
    "        cat.fit(sample_train.iloc[:,:-2].values, \n",
    "                sample_train.iloc[:,-2].values, verbose=False)\n",
    "        y_predict = cat.predict(sample_test.iloc[:,:-2].values)\n",
    "        results.append(metrics_list(sample_test.iloc[:,-2].values, y_predict))\n",
    "    if verbose:\n",
    "        print(f'Using {pos_sample_len}/{len(pos_ind)} as positives and unlabeling the rest')\n",
    "        print('target variable:\\n', mod_data.iloc[:,-1].value_counts())\n",
    "        print(neg_sample.shape, pos_sample.shape)\n",
    "    return np.array(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using 164/1639 as positives and unlabeling the rest\ntarget variable:\n -1    17734\n 1      164\nName: class_test, dtype: int64\n(164, 10) (164, 10)\n"
     ]
    }
   ],
   "source": [
    "cv_results = some_fake_cv(data, cv=8, percent=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_results(cv_results, cv=1):\n",
    "    print('Classification results:')\n",
    "    for i, score in enumerate(('f1', 'roc', 'recall', 'precision')):\n",
    "        print(f'{score}: {cv_results[i].mean()*100:.3f}% +- {cv_results[i].std()*100/np.sqrt(cv):.3f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification results:\nf1: 83.143% +- 3.332%\nroc: 82.716% +- 3.094%\nrecall: 83.361% +- 3.190%\nprecision: 83.310% +- 3.362%\n\n"
     ]
    }
   ],
   "source": [
    "print_cv_results(cv_results, cv=8)"
   ]
  },
  {
   "source": [
    "тут погрешность за 8 опытов, посомтрим на стандартное отклонение."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Classification results:\nf1: 83.143% +- 9.424%\nroc: 82.716% +- 8.750%\nrecall: 83.361% +- 9.023%\nprecision: 83.310% +- 9.509%\n\n"
     ]
    }
   ],
   "source": [
    "print_cv_results(cv_results, cv=1)"
   ]
  },
  {
   "source": [
    "По полученным результатам мы видим, что дисперсия чуть больше чем чудовищная. Сделаем побольше опытов что бы посмотреть среднее значение метрика работы такого классификатора."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=14.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78fde0707ee84a3b97025618b7a1133f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nWall time: 38min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import notebook\n",
    "percents = np.linspace(0.05, 0.7, 14)\n",
    "cv = 50\n",
    "results_for_graph = dict()\n",
    "for percent in notebook.tqdm(percents):\n",
    "    results_for_graph[percent] = some_fake_cv(data, cv=cv, percent=percent, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percent of positive class samples have been taken: 0.05\n",
      "Classification results:\n",
      "f1: 77.373% +- 2.205%\n",
      "roc: 75.738% +- 2.470%\n",
      "recall: 81.956% +- 1.501%\n",
      "precision: 84.184% +- 1.049%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.1\n",
      "Classification results:\n",
      "f1: 83.218% +- 1.451%\n",
      "roc: 73.702% +- 2.639%\n",
      "recall: 80.996% +- 1.742%\n",
      "precision: 83.169% +- 1.368%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.15\n",
      "Classification results:\n",
      "f1: 81.597% +- 1.529%\n",
      "roc: 84.106% +- 1.239%\n",
      "recall: 81.873% +- 1.498%\n",
      "precision: 81.561% +- 1.739%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.2\n",
      "Classification results:\n",
      "f1: 80.964% +- 1.784%\n",
      "roc: 79.671% +- 2.053%\n",
      "recall: 81.234% +- 1.755%\n",
      "precision: 81.349% +- 1.817%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.25\n",
      "Classification results:\n",
      "f1: 80.057% +- 1.946%\n",
      "roc: 81.235% +- 1.795%\n",
      "recall: 81.711% +- 1.686%\n",
      "precision: 81.517% +- 1.666%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.3\n",
      "Classification results:\n",
      "f1: 79.596% +- 2.003%\n",
      "roc: 80.096% +- 1.935%\n",
      "recall: 79.376% +- 2.038%\n",
      "precision: 80.160% +- 1.874%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.35\n",
      "Classification results:\n",
      "f1: 82.637% +- 1.515%\n",
      "roc: 78.696% +- 2.081%\n",
      "recall: 78.313% +- 2.170%\n",
      "precision: 80.936% +- 1.945%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.39999999999999997\n",
      "Classification results:\n",
      "f1: 79.749% +- 2.065%\n",
      "roc: 80.725% +- 1.636%\n",
      "recall: 82.354% +- 1.651%\n",
      "precision: 79.464% +- 2.053%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.44999999999999996\n",
      "Classification results:\n",
      "f1: 78.740% +- 2.130%\n",
      "roc: 79.615% +- 2.041%\n",
      "recall: 79.401% +- 2.027%\n",
      "precision: 79.437% +- 2.064%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.49999999999999994\n",
      "Classification results:\n",
      "f1: 76.982% +- 2.498%\n",
      "roc: 77.117% +- 2.351%\n",
      "recall: 77.629% +- 2.260%\n",
      "precision: 77.919% +- 2.288%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.5499999999999999\n",
      "Classification results:\n",
      "f1: 76.186% +- 2.676%\n",
      "roc: 77.519% +- 2.420%\n",
      "recall: 76.820% +- 2.440%\n",
      "precision: 78.761% +- 2.115%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.6\n",
      "Classification results:\n",
      "f1: 76.391% +- 2.475%\n",
      "roc: 76.089% +- 2.552%\n",
      "recall: 75.518% +- 2.529%\n",
      "precision: 74.695% +- 2.713%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.65\n",
      "Classification results:\n",
      "f1: 75.669% +- 2.587%\n",
      "roc: 74.079% +- 2.715%\n",
      "recall: 76.962% +- 2.493%\n",
      "precision: 76.036% +- 2.694%\n",
      "\n",
      "Percent of positive class samples have been taken: 0.7\n",
      "Classification results:\n",
      "f1: 72.148% +- 2.977%\n",
      "roc: 72.385% +- 2.977%\n",
      "recall: 71.259% +- 3.116%\n",
      "precision: 74.526% +- 2.670%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for percent in percents:\n",
    "    print(f'Percent of positive class samples have been taken: {percent}')\n",
    "    print_cv_results(results_for_graph[percent], cv=cv)"
   ]
  },
  {
   "source": [
    "Единственно что видно, что при увеличении размера первоначальной положительной выборки качество начинает падать. Скоерй всего из за дисбаланса классов, когда мы берем почти все данные позитивного класса, мы обучаем соседнюю с ним негаивную зону, чем сильно уменьшаем наши характеристики добавляя много неправильнвых ответов в наша класс."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Вы рассказывал и что более модным является 2-step approach. видимо он более переспективен, но скорей всего им можно перобучиться так как он более сложный."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}